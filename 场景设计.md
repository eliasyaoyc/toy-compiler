1G 内存中找10G文件里重复数字
hash 思想

1. 读10G文件，每次最多读1G到内存中，然后进行hash，这样可以保证相同的数字在同一个hash文件中
2. 然后判断hash文件大小，文件过大的hash文件重新hash，确保最终的hash文件小于 1G 甚至更小，因为需要为程序预留处理的内存
3. 然后分别统计分别输出

-----

现有 100GB url 文件
仅有 1GB 内存情况下（硬盘无大小限制）
需计算出现次数 top100 的 url 和出现的次数

可以通过 mapreduce 的方式去做，开启多个worker 平分 1GB 内存，然后分别去读取文件，然后统计数据 url-count,然后进行合并统计，就能计算出来了

-----

设计一个秒杀系统
整个流程
这个流程也适用于所有的高并发的场景
lvs(负载均衡, 十万界别转发) -> ngnix(负载均衡, 数万转发) -> ngnix可以限流 -> 到达服务 -> 风控考虑 -> 服务隔离的考虑 -> 限流和熔断的考虑 -> redis集群(rp+clu) -> 其中可能用lua实现原子性的批量操作 -> mq(消峰, 确保发送成功) -> 下游做幂等 -> mysql(事务) -> 确定成功之后才commit

当我们谈论秒杀, 说的是一瞬间海量的并发, 已经海量并发下的一致性(避免超发)
海量并发需要抗量银弹redis, 而秒杀就是redis使用的比较复杂的场景，而且需要大量中间件和业务逻辑去配合
我们假如有100万人, 抢100个东西

负载均衡:
高流量我们必须在请求到达你的服务之前做好负载均衡, 一个ng抗几万, 这里需要lvs做七层
1.dns绑定运营商, 找到lvs
2.lvx七层负载均衡到ngnix
3.ngnix负载均衡到你的多实例的服务
如果有必要, 你的ng还要做好限流

服务:
流量到达你的服务之后, 第一步是要考虑风控, 考虑一些过滤的原则, 比如ip过滤
然后考验的是你服务的健壮性, 最好方法是你的服务单独部署, 并且尽可能做的薄, 薄的意思是尽可能的拆分, 比如静态资源放ng或者直接走cdn
然后服务仅仅处理核心的db操作, 尽可能增加并发量
如果有必要, 当然你的服务还要做好限流和降级和熔断

db:
redis效率更高,我们这里只讨论用redis维护商品信息,然后异步的用mq去登记mysql进行数据落地.(当然也可以使用redis做分布式锁, 然后mysql维护商品信息)
单机的redis 3-4万的qps还是能顶得住的, 我们有100万, 这里肯定需要集群, 除了集群, redis的鲁棒性需要考虑, 比如出现了雪崩, 击穿, 穿透, db一定挂掉, 后果很严重
解决: 主从同步、读写分离，我们还搞点哨兵，开启持久化直接无敌高可用

超发:
我们的商品数量维护在redis, redis醉了集群和读写分离, 性能是有保证的, 但是既然用到了集群, 就一定有不同的redis直接的数据不一致的问题, 因为无论如何数据同步需要时间
解决方法是用redis的事务, 写的时候一律用lua, 用来维护一致性, 避免超发

⭐ 这里要注意的是如果使用 Redis Cluster 的话 并不支持 事务和 lua 脚本，所以的话 当我们要使用 lua 脚本来做一些原子性操作的话，我们需要预先维护这些key 在哪个node 上，然后用lua脚本指定去哪个node 上执行

mq削峰:
redis操作完成之后, 订单信息可以通过mq异步落地mysql, 提高服务的效率

链接暴露给恶意流量可乘之机:
动态url, 前后端配合加密, 然后前端js编译, 增加黑产难度

-----

设计一个 twitter
背景:
用户可以follow其它用户, 被follow的用户如果发贴, 要按照时序出现在foller的timeline里
经验告诉我们, 很明显这是一个读比写频繁的分布式系统

拉:
1.用户发帖 -> 写不频繁 -> 直接落db -> 拿到主键 -> 同时写redis做缓存
2.用户的所有followr 维护在redis, list, 做持久化存储
3.每个用户的timeline的文章列表, 按天存在redis -> key=<userid>_<this_day_first_timestamp>
4.用户发帖 -> 帖子id写进所有follwer的当天的timeline
5.用户刷新朋友圈 -> redis -> 3 -> key不存在 -> 异步将昨天的key落db(非关系型) -> key存在有缓存读缓存, 没缓存读db再缓存

-----

设计一个抽奖



-----

设计一个抢红包



-----

缓存数据库一致性问题
首先要明确的一点是不管是先写数据库还是先写缓存，在并发请求的过程中，由于网络等其他问题都会导致数据不一致问题
先删除缓存值再更新数据库 -> 先把缓存删了，还没更新数据库，并且有并发读请求，这样的话后续请求都读取旧值 -> 延迟双删，延迟一段时间后在删一次缓存
先更新数据库再删除缓存 -> 先更新数据库还没来得及删除缓存，有并发读请求，还是读到旧值 -> 等待缓存删除完成，期间会有短暂的数据不一致性情况

一般上面不管是先删除缓存还是先更新数据库都会有数据不一致性问题，可以采用如下两种方式：
延迟双删：就是把删除缓存的操作放入一个延迟队列
CDC 同步：这个就是比较烦琐，比如通过 canal 订阅 mysql binlog 变更，发生变更之后上报给 kafka，系统监听kafka 的topic 触发缓存失效

-----

关于高并发的一个通用措施
1.动态资源和静态资源分离, 绕开cgi
2.cdn, 绕开http通用网络节点
3.负载均衡
4.各种缓存
5.数据库读写分离和分库分表
6.服务分布式部署
7.合理使用各种异步, 比如消息队列削峰
或者换个角度:
前端: 自身性能优化(减少, 减小, 缓存, 和代码风格, 懒加载) + cdn
网络: dns服务器的优化(云服务商考虑的东西)
后端: 动静分离+ 负载均衡 + 异步io + 分布式部署
数据层: redis or memorycache 缓存
存储: redis集群replication+cluster集群 + mysql读写分离(主从主主)

