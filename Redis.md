关于 Redis 的整体架构

1. 单机模式：数据量不大，redis 做缓存，承担一定的并发
2. replication + sentinal：即主从+哨兵模式，一主多从，主从同步，数据完全一致，读写分离，三个以上的哨兵保证高可用
3. cluster： cluster + 主从（一主两从，备份容灾高可用）

首先需要明确的是，redis 的单线程能这么快并不仅仅因为它在内存中操作的，它的数据结构在对字节的压缩也是做的非常好，比如常用的 string 内部是 sds 结构、
list 内部是 快速(压缩节点)列表，只有当满足一定条件后才会膨胀到 list；还有的话就是redis 通过多路复用来提高网络层的性能

- 也就是说所有的事件：比如 writeevent、acceptevent、readevent 都会被放入事件处理队列中，然后由redis 主线程一个一个的处理，所以当有bigkey 的时候会堵塞
  ⭐ - 在 6.0 之后引入了多线程，这个多线程并不是说 redis 是多线程操作了，它从堵塞队列中获取事件进行socket 解析的时候这里是多线程执行，但是真正处理的时候
  还是主线程执行，包括写会socket 也是多线程。
  总结来说：这个多线程只是用于网络层面（解析请求和写回socket），真正执行的还是单线程。
    - 6.0 来引入了客户端缓存，通过普通模式、广播模式来维护客户端的缓存，避免一直进行io操作
    - RESP 3 协议

-----

关于 热key
什么是: redis集群分布式, 某台redis的某个key被极高频率的使用, 这个key则被称为热key
会发生的问题: 流量过于集中, 达到这台物理机io上限, 然后这台物理机大量请求失败, 打挂db
怎么改进:
1.监控proxy, 自动发现, 做二级缓存(bt策略, localcache)
2.如果提前知道哪些是热key, 业务层在写key的时候, 在多个redis上都存一份, 方法是(https://www.cnblogs.com/rjzheng/p/10874537.html)

雪崩
什么是: 大量的key同时或者近乎同时失效
改进: 合理设置过期时间(永不过期; 或者不同的key的过期时间加上随机数)

击穿
什么是: 并发量很大的key失效
改进: 合理设置过期时间, 互斥锁(只允许一个进程设置缓存读db)

穿透
什么是: 大量请求缓存和db中不准在的数据
改进: 布隆过滤器, 阻拦非法请求

-----

关于 Redis 的数据结构
首先 Redis 包含很多数据结构如下，Redis 单线程之所以这么快的原因也是因为它对数据结构的设计.
在客户端发送一个插入指令的时候会被封装成 RedisObject 的一个结构体，并且会用一个哈希表叫做 dict
来保存所有的键值对 dict -> redisObject -> String、List、Hash...

15 个字节 + 一个指向该数据的内存地址的指针
typedef struct redisObject {
unsigned type: 4
unsigned encoding: 4
unsigned lru:LRU_BIS  # 24 bit -> 3 个字节
int refcount
void *ptr  
} robj

里面有一个 type 字段是4个字节，用来表示这个 redisObject 是哪个类型的，比如是 String、List、Hash 等

> String: 在底层是一个 sds 简单的动态字符串，通过尾部 \0 截止符保证了二进制安全
>      它需要 8个字节的元数据分别是 已使用长度和实际分配长度，有一个区分是如果这个字符串长度小于 44 个字节那么
>      整个sds 会和 redisObject 放在一起就是一个连续的内存区域，可以避免内存碎片
>      反之就会分开。
>      ❤️ 问题：如果有大量的数据要存入，比如明明存入的数据只有 8个字节，但是会发现使用 String 会膨胀到 64 个字节，
>            这种情况建议使用 zipList
> List: 底层数据量小的时候使用 ziplist 压缩列表； ziplist 就是一个 kvkv 的紧凑数据结构
> Hash: 底层数据量小的时候使用 ziplist 压缩列表
> Set:  也是压缩列表，当元素个数超过 512 个之后会膨胀到 无value 的hash
> ZSet: 底层数据量小的时候使用 ziplist 压缩列表；数据量大的时候是 跳表结构，不使用红黑树的原因是 zset 支持范围查询 红黑树范围查询复杂度为On
>    在使用 zset 的时候，需要注意元素个数 超过128 或者 有单个元素的字符串长度超过64 就会膨胀到 跳表。可配置
> Stream:
> Geo:
> HyperLogLog:
> BitMap:
> BloomFilter: 对key进行多次hash，得到的index，去通过bit存储的一个集合中查找是否都命中，都命中则一定存在反之不一定，会存在误差

注意：当 Redis 进行扩容的时候需要非常注意，当心OOM，因为这些数据结构保存在redisObject中，而redisObject 保存在 dict 字典中
在发生扩容的时候 redis 会把当前所有的 dict 在复制一遍通过渐进式hash 的方式进行转移，如果 redis 中的数据很多，那么就有很可能发生oom，
什么是渐进式hash：相比较于 hashmap，concurrenthashmap 的高分位hash，渐进式hash 并不是直接进行转移的，是为了不影响redis 主线程(因为redis 是单线程)
如果接受到指令对某个对象操作了，则会把这个对象移到新的 dict 中，并删除老dict，如果没有接受到指令则会自己慢慢的移动并删除。
所以在发生hash的时候会突然一下子内存暴增，需要注意。所以在数据量很大的情况下并且出现这种情况，监控有毛刺了内存不健康了，可以考虑切cluster

-----

⭐ 关于 Redis 的持久化和主从同步

首先需要明白的概念是：redis 启动之后，读写都是在内存之中，只要不关机或者崩溃那么就一直在，持久化存储指的是 redis 也会保存一个文件，当redis 因为某些原因关掉后重启可以恢复数据的， redis 有两种持久化方式 rdb 和 aof，前者存的是二进制的数据，而 aof 存储的是对redis 操作的命令

rdb
全量复制，都是二进制的数据
save 900 1   # 900 秒内如果有1个key 被修改了，则发起快照保存
save 300 10  # 300 秒内如果有10个key 被修改了，则发起快照保存
实现原理：当触发 rdb 的时候会fork 出一个子线程，父线程继续处理客户端操作，而子线程用来将内存写入临时文件，然后刷磁盘
优势：

1. 一旦采用该方式，那么整个redis 数据库只包含一个文件，方便进行备份
2. 恢复速度更好，直接载入即可，aof 需要执行命令
3. 性能更高，父进程在保存 rdb 文件时唯一要做的就是 fork 出子进程，然后这个子进程就会处理接下来所有保存工作，父进程无需任何磁盘io操作
   劣势：
4. 一致性很差，因为在fork 的时候，期间可能有新的数据插入，然后会导致缺少这部分新数据
5. 如果redis 很大的话，那么fork 的时候会影响整个系统io， 比如在做主从同步的时候，会影响同步的速度

❤ 注意：在进行 rdb 的时候，主线程是会堵塞一段时间的，并不是全异步的，整个rdb 分为 save(会堵塞主线程) 和 bgsave(fork出子线程)
问题：当在fork的时候，主线程接受客户端写入数据发生改变了怎么变，copy-on-write 技术，只有具体数据改变的时候，主线程会修改页表。
而原始数据还是在子线程中，就是形成了一个快照。

aof(主线程操作)
与 aof 不同的是，aof 存储的是执行过的写命令，当aof 功能开启的时候，执行的更新命令不会直接写到 aof 文件中去，而是先写到一个 aof buf 中，这个临时文件和aof文件是同步时机也是可以控制的：
appendfsync always   # 只要有更新命令就直接同步
appendfsync everysec # 每秒
appendfsync no       # 等待操作系统自己判断
❤ 注意：aof 会有一个问题就是它的日志会越来越大，redis 有一个重写策略，只保留最新的值。
重写日志通过fork 出子线程 bgrewriteaof 来完成的，有两个值会触发：1. 重写日志达到 64mb 2. 两次重写日志大小达到一定百分比没 需要同时满足
其中有两个风险：

1. redis 主线程 fork 创建 bgwriteaof 子进行时，内存需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫做进程控制块（process
   control block）。内核要把主线程的 pcb 内容拷贝给子进程。这个创建和拷贝是由内核执行，是会堵塞主线程的，而且，如果在拷贝过程中，子进程要拷贝
   父进程的页表，这个过程的耗时和 redis 实例内存大小有关，redis 实例越大，页表越大，fork执行的时间越长，堵塞的风险越大
2. bgrewriteaof 子进程会和主线程共享内存，当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作是 bigkey
   那么主线程会因为申请大空间而面临堵塞风险，因为操作系统在分配内存空间时，有查找和锁的开销，就会导致堵塞

主从同步

1. slave 启动的时候会发送一个 psync 指令给 master
2. master 接受到这个指令的时候会通过bgsave 进行 rdb 全量的复制，然后发送给slave，期间会继续接受客户端的写操作
3. slave 会直接丢弃本身的旧数据，然后载入 master 新发过来的数据
4. slave 同步完之后，会处理 master 发送过来的增量缓冲区数据
   😁 一个问题：主从库间网络断了怎么办？
   在进行一次全量的rdb 复制开销太大了，redis 是通过一个缓冲区来解决的，当与从库断开之后，会把这期间收到的写操作塞入缓冲区中，然后当从库上线之后发送psync 和当前缓冲区的 offset 发送给 master，然后master 就可以知道 slave 从哪里断开了，就无需在一次全量的发送
   但是要注意缓冲区的 oom 情况

主从同步延迟怎么排查

1. 查看是否由于网络的原因有节点频繁的重启，这会导致重选举，以及全量rdb复制
2. 查看是否有bigkey，大量过期时间的key，以及时间复杂度很高的命令比如keys mget 之类的


小米的使用:
每个机房有8个服务器, 每个服务器上都有一个redis从, 本机的tornado实例都是优先从本机的redis读
redis从和二级主之间都不做持久化, 只有一级主做持久化(rdb)
选择rdb原因: rdb和aof必须调一个, 都不是完美的, 那就选一个
从和二级主不做持久化的原因: rdb持久化会增加redis的压力, redis需要维持两个用于同步的标记位, 然后每次写rdb文件做持久化的时候, 都会fork出一个进程, 这会增加服务器的资源占用
[考虑一个情况]
二级主挂了, 会发生什么?
1.首先二级主没有持久化, 数据全没了, 从不受影响
2.二级主断网重连和一级主做持久化, 5min
3.从和二级主断网重连重新同步, load rdb文件时, 这会影响到某个机房上的所有的从的读(1min)

我们的服务器直接连的, 都是万兆光纤

-----

关于 Redis Sentinel
什么是: 当我们谈论哨兵的时候, redis集群一定是主从的模式,  哨兵是其实就是redis实例的监视进程, 哨兵的数量只有>=3时才有意义(哨兵选举需要票数>一半, 如果只有两个, 一个哨兵挂了, 就永远选出leader进而选出主redis实例),
干嘛用的: 用来保证redis 主从集群的高可用, 哨兵就是监视进程, 和redis实例的数量没有关系
过程:
1.每个sentinel节点会定期向master节点发送心跳来判断master存活状态
2.如果一个sentinal发现master挂了(主观下线), 它会询问其他的sentinal, 如果超过半数都认为master挂了(客观下线), 就发起投票选举
3.一次一票, 选出sentinal-leader(这里用的是raft算法)
4.setinal-leader会根据配置来确定当下的从谁来当主(配置优先级 > 复制的offset > 启动最早的)
简而言之: master心跳 -> 主观下线 -> 客观下线 -> 哨兵选举 -> 新主确定
问题：sentinel 之间是如何互相发现的呢？
当 sentinel 初始化的时候会向 master 监听 sentinel monitor，然后这些哨兵就可以互相发现了

------

⭐ 关于 Redis 脑裂
背景：我们线上有一个主库、2个从库和三个哨兵实例，在使用过程中，我们发现客户端发送的一些数据弄丢了，这直接影响到了业务层的数据可靠性
经过排查发现这是主从脑裂导致的。
什么是脑裂: 就是主从集群中，因为网络的原因同时有两个主节点，它们都能接受写请求，而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的
客户端往不同的主节点写入数据，而且严重的话就会丢失数据
如何排查:
1. 确认是否是主从同步出现了问题，确定master 和slave 的缓冲区位移 master_repl_offset 和 slave_repl_offset 的差值，是否太大
2. 但是发现是一致的，然后排查客户端日志，发现有一个客户端在和原master 进行通信，并没有和新主库进行交互，故发现是原主库假故障导致的脑裂
什么原因: 当主库假死(由于堵塞并非crash)没有及时响应 sentinel 的心跳请求，所以sentinel 就进行了主从的切换，而这个时候原主节点又开始处理请求了
这就出现了一部分数据丢失了
怎么解决: 通过两个配置来解决
1. min-slaves-to-write: 设置了主库能进行数据同步最少从库数据
2. min-slaves-max-lag: 设置了从库间进行数据复制时，从库发送 ack 消息的最大延迟（以秒为单位）
其意思就是，假设这两个参数为 N 和 T，主库连接的从库中至少有 N 个从库和主库进行数据复制时的 ACK 消息延迟不超过 T 秒，否则，主库拒绝接受客户端请求

-----

关于 Redis Cluster

-----

Redis 的内存碎片问题
什么是：内存碎片由于系统分配内存并使用之后进行回收之后产生的一些不连续的内存
可以通过 info memory 命令来查看 redis 的内存使用情况
INFO memory

# memory

used_memory: 121212123123     已使用的内存
used_memory_human: 1024.00M
used_memory_rss: 190898989899 系统分配内存
used_memory_rss_human: 1.86G
如果 used_memory_rss / used_memory 的值 > 1.5 就需要清理内存，通过如下配置来调整回收内存碎片

- active-defrag-ignore-bytes 100mb: 表示内存碎片的字节数达到100mb时，开始自动清理
- active-defrag-threshold-lower 10: 表示内存碎片空间占系统分配给 Redis 的总空间达到10%时就自动清理
  ⭐ 尽可能减少碎片清理对 Redis 正常请求的影响（占用CPU）
- active-defrag-cycle-min 25 自动清理过程中所用的 CPU 时间的比例不低于 25%，
- active-defrag-cycle-max 75 自动清理过程中所用的 CPU 时间的比例不高于 75%，

-----

Redis 的数据倾斜问题
什么是：首先在不管是 sentinel 还是 cluster 都会存在数据倾斜的问题，主要就是大量的数据访问都集中到了一个node上
什么解决：
1. 首先要避免 bigkey，如果这个key 的数据就很大，那么可以进行数据拆分
2. cluster 的 slot 尽量不要分配到同一个实例上
3. 对一些热点数据，可以通过冗余的做法，把这些热点数据进行复制，然后分散到不同的node上

-----

Redis 的内存淘汰策略

- Noevction 不进行内存淘汰，内存写满了之后直接抛错，不在提供服务
- lru 留最近使用的数据
- lfu 留使用次数最高的数据
- random 随机
- ttl 根据过期时间先后进行删除

🐱 Redis 对 lfu 这个策略进行了优化，这是因为单单使用 lfu 的话，很可能


-----

Redis 的事务
MUITI 开始一个事务
EXEC 提交事务，从命令队列中取出提交的操作命令，进行实际执行
DISCARD 丢弃
WATCH 检测一个或多个键在事务执行期间是否发生变化，如果发生变化，那么当前事务放弃执行

-----

Redis 如何优化

1. 通过 ./redis-cli --intrinsic-latency:120 查看 120 秒内 redis 的延迟 / iperf 测量从客户端到服务的网络延迟 避免是服务器的问题
2. redis 6.0 之后加入了客户端缓存,可以使用避免发送io
3. 避免bigkey
4. 在多核cpu中，绑定core，避免线程上下文切换
5. 能使用pipeline 就是pipeline
6. 一些变慢的操作别用，比如keys 、sort、sunion、sinter啥的
7. 避免大量的过期 key，尽量把 key 的过期时间分散
8. 查看是否使用了透明大页(2MB)机制，如果是直接关闭
9. aof 配置级别，如果只需要高性能，允许数据丢失，可以把aof 重写关闭，又需要高性能和高可靠建议使用ssd