#### 关于7层与4层
* OSI 七层： 物理层(网卡设备)、数据链路层(MAC地址)、网络层(IP)、传输层(TCP、UDP)、会话层(维护连接状态、即保持会话和同步)、表示层(把数据转换为合适、可理解的语法和语义)、应用层(HTTP、FTP)
* 四层： 数据链路层、网络层、传输层、应用层
-------

#### 关于 TCP 和 UDP
1. TCP 粘包怎么处理？
>TCP 是面向流协议，发送单位是字节流，因此会将多个小尺寸数据被封装在一个 tcp 报文中发出去的可能性，
   简单的例子就是客户端调用了两次 send，服务端一个 recv 就把信息都读出来了
> 
> 可以通过 「固定长度」、「加入分隔符」来解决
> 
2. 为何 UDP 不可靠？

> 因为TCP 作为面向流的协议，提供可靠的、面向连接的运输服务，并且提供点对点通信 UDP
> 作为面向报文的协议，不提供可靠交付，并且不需要连接，不仅仅点对点，可以支持多播和广播

3. TCP 三次握手
   * 第一次握手：客户端将标志位 SYN 置为 1，随机产生一个值序列号为seq=x，并将该数据包发送给服务端，客户端进入 syn_send 状态，等待服务端确认
   * 第二次握手：服务端接受到数据包之后由标志位SYN=1知道客户端在请求建立连接，服务端将标志位SYN 和 ACK 都置为1，ack=x+1，随机产生一个值 seq=y，
               并将该数据包发送给客户端以确认连接请求，服务端进入 syn_rcvd 状态
   * 第三次握手：客户端收到确认后检查，如果正确则将标志位ACK为1，ack=y+1,并将该数据包发送给服务端，服务端进行检查如果正确则连接建立成功，客户端和服务端进入                  estalished 状态，完成三次握手，随后客户端和服务端之间就可以开始传输数据了

4. 为什么 TCP 握手需要三次
>  可以4次或者更多，但是不能少，TCP进行可靠传输就是在维护一个序列号，三次握手的过程即时是服务端和客户端互相告知序列号的起始值.
   如果只是两次握手，那么至多只有客户端的起始序列号能被确认，服务端的序列号则得不到确认，多次的话就会浪费资源

5. TCP 的滑动窗口（流量控制）
> 滑动窗口是传输层进行流量控制的一种措施，接受方通过告诉发送方自己的窗口大小，从而控制发送方的发送速度，防止发送方发送速度过快而导致自己淹没

6. TCP 的拥塞控制
> 什么是：拥塞是指一个或者多个交换点的数据报超载，TCP又会有重传机制，导致过载。为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量.
> 
> 当cwnd < ssthresh 时，使用慢开始算法。 当cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当cwnd = ssthresh 时，即可使用慢开始算法，也可使用拥塞避免算法。

> 慢开始：由小到大逐渐增加拥塞窗口的大小，每接一次报文，cwnd指数增加。
> 拥塞避免：cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1。
> 快恢复之前的策略：发送方判断网络出现拥塞，就把ssthresh设置为出现拥塞时发送方窗口值的一半，继续执行慢开始，之后进行拥塞避免。
> 快恢复：发送方判断网络出现拥塞，就把ssthresh设置为出现拥塞时发送方窗口值的一半，并把cwnd设置为ssthresh的一半，之后进行拥塞避免。

7. 快重传
> 如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK，发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出再发送该报文

8. 半连接队列
> 在 TCP 握手中，当服务器处于 SYN_RCVD 状态，服务器会把这种状态下的请求连接放在一个队列里，该队列称为半连接队列

9. SYN 攻击
> 这是利用了 TCP 协议的缺陷，通过发送大量的半连接请求，占用半连接队列，耗费CPU和内存资源
> 
> 如何解决：
> 1. 缩短  SYN timeout 时间
> 2. 记录 IP，若连续受到某个 IP 的重复 SYN 报文，从这个IP地址来的包会被一概丢弃
    
10. tcp_syncookies 该功能开启之后可以防止 SYN 攻击， tcp_synack_retries 和 tcp_syn_retries 定义 syn 的重试次数
>此功能开启之后，Server 在接受到 SYN 请求进入 SYN_RECVD 状态的时候，不在给 Client 分配数据区了，会给接受到的 SYN 请求计算一个 Cookie 值，
>当 Client 发送 ack 过来之后根据这个 Cookie 计算连接合法性然后开启数据区

❤️ **问题**
> 当开启 tcp_syncookie 之后，client 的第三次握手发送 ack 失败，然后client 第一个packet 小于 3个字节，也没有发送成功
> 在 client 任何重传发生之前， client 又发送了一个数据包成功了。
> Server 会认为第一个packet 接受到了，没有任何的感知
> 但是如果第一个packet > 3 bytes 的时候，由于 check_tcp_syn_cookie 检查，会被 reset，保证了 tcp 可靠
 
11. TCP 四次挥手
   - 第一次挥手：客户端发送一个 FIN=1 和一个 seq ，用来关闭客户端到服务端的连接，客户端进入 fin_wait_1 状态
   - 第二次挥手：服务端接受到 FIN 后，发送一个 ACK=1 给客户端，确认序列号ack 为 收到序号+1 ，seq ，服务端进入Close_wait状态。此时 TCP  
   - 连接处于半关闭状态，即客户端已经没有要发送的数据了，但服务端若发送数据，则客户端仍需要接受
   - 当客户端收到服务端的响应后，进入 fin_wait_2 状态，仅仅是服务器都到了断开请求，但是没真正同意断开
   - 第三次挥手：服务端发送一个 FIN=1 ACK=1 seq ack=收到序号+1，用来关闭服务端到客户端的数据传送，服务端进入 Last_ack 状态
   - 第四次挥手：客户端收到 FIN 后，客户端进入 Time_wait 状态，接着发送一个 ACK seq ack 给服务点，确认后，服务端进入 Closed 状态，完成四次挥手

为什么TCP 挥手需要 4 次？

> 主要原因是当服务端接受到客户端的 FIN 数据包后，服务端可能还有数据没发完，不会立即 Close
> 所以服务端会先发送一个 ACK 给客户端告诉客户端我收到你的断开请求了，但需要一点时间，这段时间用来发送剩下的数据报文，发完之后再将 FIN 包发给客户端表示可以
> 断了，之后客户端需要收到 FIN 包后 发送 ACK 确认断开信息给服务端
> 
⭐ 注意四次挥手释放连接的时候需要等待 2MSL(maximum segment liefetime 最大生存时间)，这是因为 2MSL 可以保证上一次连接的报文已经在网络中消息，不会出现与新TCP连接报文冲突的情况


12. TCP 状态位 time_wait
> 什么是：time_wait 是挥手发起方，在发送第四次挥手报文之后的状态，这个状态会持续 2MSL(Maximum Segment Lifetime)，就是报文最大生存时间
> 
> 有什么用：这是为了确定最后一次挥手报文被接受方收到，一来一回两个MSL，如果这个时候都没有再次收到挥手方接收放的第三次挥手报文,就可以认为最后一次挥手报文被成功接受到了，在 TIME_WAIT 状态时发起方的端口不能使用，要等到 2MSL 时间结束才可以继续使用，于此对应 last_ack 这个状态位也会持续两个 MSL

13. 关于 backlog
> 什么是：backlog 是一个连接队列，tcp 建立连接的时候需要进行三次握手这里分为 服务端等待接受客户端ack 的 SYN_RECV 状态称为半链接队列
完成ACK 后称为全链接队列

14. 快速打开的原理
> 什么是：快速打开简称 TFO(Tcp Fast Open)，用于提高 C-S 的打开速度，其原理是使用 SYN Cookie 实现
> 
> TFO 首轮三次握手：
> 1. C 向 S 发送 SYN 请求，S接受到之后
> 2. 不是立即返回 SYN+ACK，而是S通过计算得到一个 SYN Cookie，将这个 Cookie 放在 tcp 报文的 Fast Open 选项中，然后发送给 C
> 3. C 拿到 Cookie 后缓存下来，后面就是正常
> 
> TFO 后面的三次握手：
> 4. C 向 S 发送 Cookie、SYN、HTTP 请求
> 5. S 验证 C 的 Cookie 是否合法，如何合法，则正常返回 SYN + ACKC，否则直接丢弃请求数据
> 6. S 向 C 发送 HTTP 响应
> 7. C 还是需要回复 S ACK
> 
> 优势：TFO的优势并不在首轮的3次握手，而在于后面的握手，在S拿到C的Cookie并验证通过后，便可以直接返回HTTP响应，充分利用了1个RTT(Round Trip Time)的时间提前进行数据传输。虽然一个来回没有什么太大的提升，但是如果数据发送的越多，这优势也就越大了。

-------

### DNS 相关
> 什么是：DNS 协议是基于 UDP 的应用层协议，它的功能是根据用户输入的域名，解析出该域名对应的 IP 地址，从而给客户端进行访问

DNS 解析过程
1. 客户机发出查询请求，在本地计算机缓存查找，若没有找到，就会将请求发送给 dns 服务器
2. 本地dns服务器会在自己的区域里面查找，找到即根据此记录进行解析，若没有找到，就会在本地的缓存里面查找
3. 本地服务器没有找到客户机查询的信息，就会将请求发送到根域名 dns 服务器
4. 根域名服务器解析客户机请求的根域部分，它把包含的下一级的 dns 服务器的地址返回到客户机的dns服务器地址
5. 客户机的 dns 服务器根据返回的信息接着访问下一级的 dns 服务器
6. 这样递归的方法一级一级接近查询目标，最后在有目标域名的服务器上得到相应的 IP 信息
7. 客户机的本地的 dns 服务器会将查询结构返回给我们的客户机
8. 客户端根据得到的ip信息访问目标主机，完成解析过程


-------

### HTTP 相关
> 什么是：基于 TCP 传输层的应用层 超文本传输协议，即客户端和服务端进行数据传输的一种规则，该协议本身是一种无状态的协议

1. Cookie
   > 什么是：HTTP 协议本身是无状态的，但是我们的应用需要来保存一些状态，所以引入了 Cookie，是由服务端产生的，在发送给客户端保存，当客户端再次访问的时候，
   服务器可以根据cookio 辩识客户端是哪个，来实现一些应用。Session 也是类似的效果
   ⭐ 如何考虑分布式 Session 问题？

> 比如说用户在 A 服务器登录了， 第二次请求跑到 B 服务器就会出现登录失效
> 直接存储在客户端、 Nginx ip_hash 策略、 Session 复制（广播到其他节点）、 共享 Session(使用 Redis)

2. GET 和 POST 的区别
* Get: 指定资源请求数据，Get 请求的数据会附加到 URL 中，传输数据的大小受到 url 的限制
* Post: 向指定资源提交要被处理的数据，刷新会使数据被重复提交，post 在发送数据前会先将请求头发送给服务端进行确认，然后才真正发送数据

3. GET 方法参数有大小限制吗
> HTTP 协议并不限制参数大小，但一般由于get请求直接附加到地址栏里面，由于浏览器地址栏有长度限制，因此使 get 请求在浏览器实现层面上看会有长度限制

4. 常见错误码： 
> - 301：永久重定向 
> - 302：临时重定向 
> - 304：资源没修改，用之前缓存就行 
> - 400：客户端请求的报文有错误 
> - 403：表示服务器禁止访问资源 
> - 404：表示请求的资源在服务器上不存在或未找到

5. HTTP1.0、 HTTP1.1、HTTP2.0 的改进

> HTTP1.0： 规定了请求头和请求尾，响应头和响应尾，每一个请求都是一个单独的连接，做不到连接的复用
> HTTP1.1： 默认开启长连接，在一个 TCP 连接上可以传送多个HTTP 请求和响应，使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销
>        支持管道 pipeline 网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。
>        服务端无法主动 push
> HTTP2.0： 多路复用，可以同时传输
>        引入了二进制数据帧，其中帧对数据进行顺序标识，有了序列id，服务器就可以进行并行传输数据

6. HTTP 短连接与长连接的区别
> HTTP 中的长短连接指的是 HTTP 底层 TCP 的连接
- 短链接：客户端与服务端进行一次HTTP连接操作，就进行一次TCP连接，连接结束 TCP 关闭连接
- 长连接：如果HTTP 头部带有 keep-alive，即开启长连接网页完成打开后，底层用于传输数据的 TCP 连接不会直接关闭，会根据服务端设置的保持时间保持连接，
         保持时间过后连接关闭

7. HTTPS 的连接过程

> 浏览器将支持的加密算法信息发给服务器
> 服务器选择一套浏览器支持的加密算法，以证书的形式回发给浏览器
> 客户端(SSL/TLS) 解析证书验证证书合法性，生成对称加密的密钥，我们将该密钥称之为 client key 即客户端密钥，用服务器的公钥对客户端密钥进行非对称加密
> 客户端会发起 HTTPS 中的第二个 HTTP 请求，将加密之后的客户端对称密钥发送给服务器
> 服务器接受到客户端的密文之后，用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文
> 服务端将加密的密文发送给客户端
> 客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据，这样HTTPS 中第二个HTTP 请求结束，整个HTTPS 传输完成

-------

浏览器中输入一个网址后，具体发生了什么
> - 比如 www.baidu.com, 会先根据 DNS 解析操作，根据 DNS 解析的结果查找服务的 IP 地址
> - 通过 IP 寻址 和 ARP(地址协议解析)，找到服务器，并利用三次握手建立 TCP 连接
> - 浏览器生成 HTTP 报文，发送 HTTP 请求，等到服务器响应
> - 服务器处理请求，并返回给浏览器
> - 根据 HTTP 是否开启长连接，进行 TCP 的挥手过程
> - 浏览器根据收到的静态资源进行页面渲染

------

DDos 攻击
> 什么是：全称为 Distributed Denial of Service，分布式拒绝服务攻击，类似 SYN 攻击，但是 DDos 是分布式的，通过多台服务器一起进行攻击
> 
> 如何预防：
> - 减少 SYN timeout 时间，在握手的第三步，服务器会等待30秒-120秒的时间，减少这个等待时间就能释放更多的资源
> - 限制同时打开的 SYN 半连接数量
> - 记录访问 IP 多次相同的访问，直接拒绝

------

XSS 攻击
> 什么是：cross-site scripting，跨站脚本攻击。 通过技术手段，向正常用户请求的 HTML 页面中插入恶意脚本，执行分为反射型和存储型
> - 反射型：指诱导用户点连接，比如获取cookie
> - 存储型：值用户提交表单的时候，把伪造的 js 塞进去，那么以后无论谁在访问这个数据，都会执行 js 造成工程
          比如一个存在 XSS 漏洞的论坛，用户发帖时就会带有 </script> 标签的代码，导致恶意代码的执行
>
> 如何避免
> - 前段过滤
> - 后端转义，比如go 自带的处理器具有转义功能

-----

csrf 攻击
> 什么是：cross site request forge 跨站请求伪造
> 
> 原理： 用户访问安全的A 拿到 A 的 cookie -> 访问不安全的B，B通过用户携带的A的cookie 恶意表单请求 A
> 
> 怎么解决：
> - get > post，增加暴露难度
> - cookio 过期设短
> - refer 做限制
> - 危险操作验证码，确定是成本高
> - 用 token(jwt)

-----

跨域
> 什么是： CORS 跨域资源共享，跨域请求就是值当前发起请求的域与该请求指向的资源所在的域不一样。这里的域指的是这样的一个概念：我们认为若协议 + 域名 + 端口号
> 均相同，那么就是同域。
> 
> 怎么解决：JSONP，但是比较常用的可以在 HTTP 头加入比如 Access-Control-Allow-Origin 等参数

------

SQL 注入
> 什么是：用户输入的字符串中加入 SQL 语句，那么就可以执行非预期的 SQL 语句获取未授权的数据
>
> 如何避免：
> - 限制数据库权限，给用户提供仅仅能够满足其工作的最低权限
> - 对进入数据库的特殊字符('"&* 等) 进行转义处理
> - 提供参数化查询接口，不要知己诶使用原生 SQL

------

cdn
> 什么是：内容分发网络
> 
> 作用：cnd 是构建在现有网络基础上的只能虚拟网络，依靠部署在各地的边缘服务器，为用户提供最近的服务，更高效，能容灾
> 
> 原理：之前买腾讯云 cdn 加速的时候，研究过，假设我现在要请求一个图片资源的域名
> 
> 域名 -> dns -> dns 发现这个域名配置了 cdn(cname) -> 取出 cname 到 cdn 专属的一个 dns 服务器(腾讯云实现的)解析出一个 ip地址
> 这个ip地址就是上边说的离用户最近的服务器的地址 -> 判断此服务器上有没有资源 -> 有资源直接返回 -> 没资源回源站取 -> 然后缓存

-------

jwt
>什么是： json web token
> 
>有什么用： 类似session 的作用，可以用来验证请求，或者保存用户信息，还可以避免 csrf

--------
### 关于 IO 模型相关
> 前提：要明确同步和堵塞的含义
> * 是否同步：同步就是触发io操作会不端的去查询或者轮询是否就绪，而异步是指用户进程触发io操作后变开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知，需要CPU支持
> * 是否堵塞：读取或者写入方法将一直等待，而非堵塞方式读取或写入方法会立刻返回一个状态值

**同步堵塞IO**
1. 用户态调用 recvfrom 系统调用内核，在这里会堵塞住
2. 如果内核没有所需要数据，则会等待，直到数据准备好了，进行返回
   典型的 Java 中 BIO

**同步非堵塞IO(配置 socket 非堵塞方式就行设置为 NONBLOCKING)**
1. 用户态调用 recvfrom 系统调用内核
2. 内核不管有数据还是没数据都会立马返回
3. 没有数据则会再次调用 recvfrom 再来一次
   进程轮询，消费cpu资源
   
**IO 多路复用：select、poll 是堵塞的，epoll 的通过事件驱动实现不堵塞的**
1. 调用 select 、poll或者 epoll 来不断的轮询自己的fd是否ok
2. ok 了则调用 recvfrom 进行数据的拷贝到用户态
>在接受到信号之后通过 recvfrom 进行数据拷贝是会堵塞的
> ⭐ select、poll 它们在fd 很多的时候性能较差，它们需要把fd集合从用户态拷贝到内核态(默认是1024个fd)，然后依次遍历查看已经完成的fd(线性查找)
> epoll 每次注册新的事件它会把事件fd拷贝到内存，不会每次在调用epoll 的时候进行拷贝，它给每个fd 挂了一个回调函数，当内核发现完成就绪了直接回调对应的回调函数
> 并且 epoll 通过红黑树来管理这些 fd，避免修改 fd 的时候复杂度太高
> 
> https://mp.weixin.qq.com/s/LGMNEsWuXjDM7V9HlnxSuQ

**信号驱动IO**
1. 通过 sigio 向内核态注册一个信号
2. 内核态满足后进行回调，然后在调用 recvfrom 进行数据拷贝
   在接受到信号之后通过 recvfrom 进行数据拷贝是会堵塞的

**异步io：不堵塞，数据一步到位，Proactor 模式**
1. 调用 aio_read， 内核准备好数据知乎，直接交给用户态，不需要在调用 recv 进行拷贝         
   ⭐ 这些IO 模型中需要明确一点同步与堵塞的关系
   只有当用户态发送请求给服务端双方互补干扰都做自己的事情叫做异步
   所以说当用户线程发出 io 调用，去获取 io设备数据，双方的数据要经过内核缓冲区同步，完全准备好之后，在复制返回给用户进程，而复制到用户态缓冲区需要进程堵塞，这就是同步
   也就是说只有异步io这种io模式才是异步的，因为它是在内核态准备好数据之后直接给用户态处理的 通过mmap，简单来讲只要调用的  recvfrom这个系统调用都是同步的

**IO_uring**

