行锁与表锁的区别


-----

myisam 和 innodb 的区别

1. myisam 没有事务
2. myisam 没有行锁，只有表锁
3. innodb 主键索尼的值存的是具体的数据，而myisam 的主键索引的data 存放的是数据项的地址
4. myisam 的叶子节点存放的是具体数据的地址，innodb 存放的是主键id需要回表，而 myisam 不需要回表

-----

执行 SQL 语言的过程

1. 客户端首先通过连接器进行身份验证和权限相关
2. 如果是执行查询语句的时候，会先查缓存，8.0这步骤已被删除
3. 没有命中缓存，SQL 语句就会经过解析器，分析语句，包括语法检查等等
4. 通过优化器，将用户的 SQL 语句按照 MYSQL 认为最优的方案去执行
5. 执行语句，并从存储引擎返回数据

-----

事务隔离级别
读未提交
问题：会出现脏读，
什么是脏读：事务B 读取了 事务 A 未提交的数据，然后事务A 回滚了
读已提交
解决了读未提交的脏读
问题：不可重复读
什么是不可重复读：事务A 多次读取 事务B期间进行了修改，事务A 发现数据不一致了
可重复度
解决了不可重复读，通过 mvcc 来解决，mvcc 通过 redolog 来实现，每条log 都有一个版本号
问题：幻读
什么是幻读：事务A 多次读取 事务B 期间新增的数据，事务A 发现数据总数不一致性了
在 mysql 的 innodb 中通过 gab 间隙锁来解决了幻读问题
⭐ 并不是完全可以通过 gab 间隙所来解决这个幻读问题，有两种情况的：
—— 快照读可以通过 mvcc 来解决
—— 当前读需要通过 gab 或者 next-lock 来解决
唯一索引的话是只会加行锁，范围的话使用用 next-key 锁（gab 锁 + 行锁）
得出的结论：基本不会出现，但是需要记住的是 唯一索引是不会走 next-key 锁的
串行化
问题：性能太差
⭐ 问题我们公司在使用乐观锁的时候用了读已提交的方式来做，因为我们是把 version 字段先查出来然后通过业务进行判断是否插入
这种方式使用 可重复度这种隔离级别的话，会出现数据覆盖的问题。
为什么：因为 RR 通过 MVCC 来解决了不可重复读的问题，读分为两种 当前读(delete、update)和快照读(select)
所以说在RR 中 select 会快照读，如果一个事务过来快速的修改了数据把version + 1 了，那么就会读到旧的version
导致数据被覆盖，所以这种情况得使用读已提交，强制当前读

-----

mysql 优化的经验
关于底层的优化都是 DBA 在做，比如一些配置啥的。

1. 要合理使用myisam 和 innodb 引擎
2. innodb 每个表的主键且类型必须是 bigint, 这是为了建立聚簇索引提供方便
3. 查询频繁字段，必须建议索引，并且索引字段应该尽可能的小
4. 尽量不要用外键，而是靠服务去维护关系，因为 mysql 维护需要成本
5. text 字段 not null
6. 注意 left join（左表全） / right join（右表全） / inner join（都不全） 的区别

数据库的查询优化、排查慢sql以及sql优化是怎么进行的？详细点说一下
一般是看这个sql 有没有用一些没有走索引的操作，比如like 比大小，left right 的使用，is null，or啥的
然后在explain 看走的哪个索引，是否走了正确的索引，还有就是在orderby的时候也要注意因为orderby 会把数据放到内存，
可以通过参数限定orderby 放到内存的条数

-----

mysql 不走索引的情况

1. 索引项参与计算比如+1，函数，正则表达式，比大小
2. 模糊查询 like，is null 也不走索引，类型转换
3. or，所有的or都不走索引，可以用 union代替(select * from t where country = 'z' or city = 'x' -> select * from t where country = 'z' union...)
4. 复合索引a-b-c，a用到，b，c 用不到，即索引的最左原则匹配特性

-----

mysql 什么时候用 myisam
当你不需要使用事务，不需要使用行锁，并且有大量的读操作，可以考虑myisam，因为某些情况下它的读效率更高

1. 当使用索引查询的时候（这个索引不是 innodb 的聚集索引），myisam 的叶子节点查到的是数据项的地址，而 innodb 是聚集索引的值，需要进行回表
2. 索引可以压缩，效率更高
3. myisam 支持全文的模糊查找，like 效率更高

-----

关于 binlog、undolog、redolog
https://blog.csdn.net/u010325193/article/details/86586530
什么是：
binlog: 是mysql 层面的日志，记录了当前mysql 历史上所有的更新操作和隐式的更新操作
undolog和redolog: 是事务相关的日志，所以只和innodb 相关，undolog 记录了事务提交之前的相关数据项的值，redolog 记录了事务提交后的相关数据项的值
有什么用：binlog 可以用来容灾备份，也可以用来主从同步
undolog 和 redolog 用来保证事务的一致性，和原子性，undolog 还用于 mvcc

-----

mysql 的 orderby
前提：查找的时候有索引查索引，没索引要全表查询
select city、name、age from t where city = '杭州' order by name limit 1000;
整个查询过程：查询二级索引 city = '杭州' 主键 -> 通过主键查询聚簇索引获取整条数据并且取出（id,city,name,age）-> 将数据放在内存中排序 ->      
如果超过预设的排序内存的代销 -> 借助硬盘文件来排序 -> 如果数据太多，还会被分到多个文件然后合并的问题
问题：在上面的过程中所有的开销都在回表和内存中排序的开销
解决优化：
- 内存中的开销问题，max_length_for_sort_data 设小，每个数据项只包含了 name 和 主键
- 或者直接使用联合索引（city,name），两个问题都可以避免

----

sql 的优化：
首先 explain 查看是否走索引，或者根据整条sql 判断是否走了最优的索引

1. 在 where 和 orderby 上建立索引
2. 索引字段要尽量小
3. 合理使用行锁表锁，增加并发量
4. 避免大事务
5. 合理选择引擎，偏重读选 myisam

-----

mysql B+树的高度
假如一个B+树的节点有m个值，那么就是 m+1 个叉，高度就是 log(m+1)n

-----

关于外键
外键是用来建立表和表之间的数据关系和约束
注意：

1. 一个表的外键必然是一个表中的主键
2. 外键约束能防止非法数据插入外键列，因为它必须是它指向的那个表中的主键
3. 外键约束也用于预防非法删除

-----

mysql 的一对一，多对一，多对多
一对一：外键唯一约束
多对一：外键不唯一约束
多对多：借助中间表，搞成两个一对多，比如老师表、学生表、中间关系表

-----

mysql如何建立一对一, 一对多, 多对多的关联关系


-----

关于 mysql 的分库分表
什么是：分库分表是为了解决大表对数据库系统的压力
干什么用：分表是用来解决单表 io 的瓶颈，分库是用来解决 dbio的瓶颈
怎么分：水平分表库，垂直分表库
⭐ 注意：
- 1000w以内的表，不建议分，通过合适的索引，读写分离等方式，可以很好的结局
- 分表会加 sql 跨表的可能性，跨表会影响性能；分裤没办法连表查询，不能使用事务，只能通过业务来解决

垂直拆库 -> 对一些不同业务的进行拆分，比如用户一个库，商品一个库
垂直拆表 -> 对一些不常用的字段或者数据较大的字段拆分到「扩展表」，可能对单表的压力会比较大
水平拆库 ->
水平拆表 -> 基于全表常见的是基于用户id 进行切分，缺点：事务一致性问题、join 性能差
- 基于hash 取模，简单，但是需要预先判断需要分多少张表，后期扩容麻烦
- 基于range，缺点 热点数据容易成为 瓶颈

-----

关于 mysql 事务并发产生问题用锁解决

> 事务并发，不同的事务隔离级别，会产生不同的问题
> 为了解决问题 > 引进了乐观锁悲观锁
> 乐观锁由程序员实现 > 悲观锁是 mysql 的机制
> 悲观锁分为读锁和写锁 > 即共享锁和排它锁
> 共享锁和排它锁都用事务中间，commit 之后释放锁
> 共享锁 lock in share mode，一个事务给一行加了共享锁，其他事务也可以加，都只能读，不能写
> 排他锁 for update，一个事务给一行加了排它锁，其他事务不能加任何锁，不能读不能写

-----

Innodb 如何保证事务的原子性、持久性和一致性？

- 利用 undo log 保障原子性，该 log 保存了事务发生之前的数据的一个版本，可以回滚
- 利用 redo log 保证持久性，该 log 关注于事务的恢复，保存了事务提交后的版本，用来恢复
  ⭐ 注意 redolog 和binlog 是有区别的
  redolog 是 Innodb 持有的，只记录该引擎中表的修改记录，binlog 是 mysql 实现的会记录所有引擎对数据库的修改
  redolog 是物理日志，记录了具体在某个数据页上做了什么修改，binlog 是逻辑日志，记录这个语句的原始逻辑
  redolog 是循环写的会写完并覆盖以前的，binlog 可以追加写入的

-----

关于 WAL
什么是：write-ahead logging，在写入磁盘的过程中预先写入日志，在写磁盘。事务在提交写入磁盘前，会先写到 redo log 里面去。
如果直接写入磁盘涉及磁盘的随机 IO 访问，这是比较耗时的，相比较先写入 redo log ，然后在找合适的时机批量刷盘能提高性能

-----

关于 mysql 中的 2pc
是什么：为了保证 binlog 和 redolog 两份日志的逻辑一致，最终保证恢复到主备数据库的数据是一致的，采用两阶段提交的机制
1: 调用存储引擎接口，存储引擎将修改更新到内存中后，将修改操作记录 redolog 中，此时redo log 处于 prepare 状态
2: 存储引擎告知执行器执行完毕，执行器生成这个操作对应的 binlog，并把binlog 写入磁盘
3: 执行器调用引擎提交事务接口，引擎把刚刚写入的 redo log 改成提交 commit 状态，更新完成

-----

关于 mysql 集群
https://www.cnblogs.com/ExMan/p/11238593.html

-----

关于 mysql 是如何保证主备一致性的
主要是通过binlog(不会记录 select 、show 这种不修改数据库的语句)，主库会有一个专门的线程用来把binlog发送给备库，有三种格式：
statement：只记录修改语句本身，优点 binlog 日志量少，io压力小，性能高； 缺点：由于记录的信息比较少，不易操作
row：会把整行数据都记录，优点数据还原度高易操作，但是io压力大
mixed：混合模式，上面两种

-----

只靠 Binlog 可以支持数据库崩溃恢复吗
答案: 不可以, 历史原因
InnoDB 在作为 mysql 插件之前，就已经有一个提供了崩溃恢复和事务支持的引擎了，Innodb 接入 mysql 之后，发现既然 binlog 没有崩溃恢复能力，那引入 innodb
原有的 redolog 来保证崩溃恢复 实现原因：
—— binlog 它只是逻辑日志，只记录这个原始逻辑，不会记录数据库对其进行什么操做，当一个事务做增删改的时，其实涉及到的数据页改动非常细致和复杂，包括行的字段
改动以及数据页头部的改动，甚至 B+tree 插入一行而发生的若干次页面分裂等这些都会被redolog 记录
—— 一个操作写入 binlog 可细分为2个操作，write 和 fsync 两个过程， write 指的是把日志写入文件系统的 pagecache，如果没有持久化刷入磁盘就crash 了那么就会
数据丢失，通过参数设置 sync_binlog 为 0 的时候，表示每次提交事务都只有 write，不 fsync。此时数据库崩溃可能导致部分提交的事务及binlog 日志由于没有持久化而丢失

-----

⭐ 关于 mysql 的索引
B+tree 索引：
B-Tree 是一种自平衡的多叉树，每个节点都存储关键字值，其左子节点的关键字值小于该节点关键字值，且右子节点的关键字值大于或等于该节点关键字值
B+Tree 是一种自平衡的多叉树，与B树相同，不同的在于数据只出现在叶子节点上，所以叶子节点添加了一个链指针，方便进行范围查询
中间节点是不放数据的，只会放key用作于索引，所以同样大小的磁盘页上可以容纳更多的节点元素，访问叶子节点上关联的数据命中率也高，并且
所有节点上的顺序都是相连的，所以便于区间查找和搜索


                  缺点：
                      - 正是因为B+树的这种设计，非聚簇索引的查询回发生回表，并且在叶子节点分裂或者在合并的过程中会出现极端的过程，可能一直分裂或者合并到根 
                        节点，每个节点在做分裂或合并的时候都会锁定所以性能会受影响，一般的操作都是会自适应的来主动的检测是否要分裂或者合并，避免大规模。
                      -  树的结构体在适用于读多写少的场景下，因为读的时候可以根据索引一下子命中具体的叶子节点，所以说读放大很低，但是树结构的写放大很严重，
                         因为它会有对一个叶子节点中间值插入的操作，那么其他值就会发生移动，可能还会发生分裂，可以类似数组操作插入一个中间值。
                     所以说对于一些读多写少的场景下，一般是不用B+树 而是用 LSM tree，比如著名的 Rocksdb    

Hash 索引： Hash 索引对于一些明确的查询比如 k="xx" 效率是非常高的，但是它不支持范围查询，无法用于排序，也不支持部分索引的匹配查询

对于覆盖索引和最左原则：
覆盖索引：一个索引包含或者覆盖了所有需要查询的字段值，比如索引 name,age  查询的 select age from t where name = t，这种情况下是不需要回表的直接能获取到
最左原则：对于联合索引的查询，会从最左侧开始查询，一只向右匹配，所以可以合并多个查询所需要的索引，把优先级最高的放带最左侧
- 如何实现的：联合索引 (col1 col2 col3) 也是一颗 B+Tree，其非叶子节点的是第一个关键字的索引，
叶子节点存储的则是三个关键字 col1,col2,col3 三个关键字的数据和数据项的主键索引，且按照 col1,col2,col3 的顺序进行排序
索引下推：其实和覆盖索引很像，就是避免回表，在二级索引进行判断是否满足查询要求，如果不满足就直接过滤避免回表

-----

mysql 主从延迟排查
产生原因：1. 由于主库写入binlog 是顺序写入的，所以效率很高，但是从库重放的时候是随机的，性能会差很多，
2. 另一方面的话mysql主从同步都是单线程操作
3. 如果有慢查询，或者sql中存在一些锁，那么就会影响从库的同步速度
解决方案：1. 优化sql，explain、left-join right-join inner-join 的觉得、order by 的使用、避免模糊查询，or查询，以及正则比大小等不走索引的操作
2. 如果5.7版本以上的话可以开启并行同步的开关
3. 提高从库的硬件
4. 优化网络

-----

group by语句实现的内部机制是什么？如何优化？
MySQL中，GROUP BY的实现有多种（三种）方式，其中有两种方式会利用现有的索引信息来完成GROUP BY，另外一种为完全无法使用索引的场景下使用。
1). 用松散（Loose）索引扫描实现GROUP BY 当MySQL完全利用索引扫描来实现GROUP BY的时候，并不需要扫描所有满足条件的索引键即可完成操作得出结果
什么松散索引扫描的效率会很高？ 因为在没有WHERE子句，也就是必须经过全索引扫描的时候，松散索引扫描需要读取的键值数量与分组的组数量一样多，也就是说比实际存在的键值数目要少很多。而在WHERE子句包含范围判断式或者等值表达式的时候，松散索引扫描查找满足范围条件的每个组的第1个关键字，并且再次读取尽可能最少数量的关键字。
2). 用紧凑（Tight）索引扫描实现GROUP BY 紧凑索引扫描实现GROUP BY和松散索引扫描的区别主要在于他需要在扫描索引的时候，读取所有满足条件的索引键，然后再根据读取的数据来完成GROUP BY操作得到相应结果。
3). 用临时表实现 GROUP BY 前面两种GROUP BY的实现方式都是在有可以利用的索引的时候使用的，当MySQL Query Optimizer无法找到合适的索引可以利用的时候，就不得不先读取需要的数据，然后通过临时表来完成GROUP BY操作。

